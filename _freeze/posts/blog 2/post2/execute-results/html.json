{
  "hash": "0946ccc10d088cd8aaee29ec8fdcf369",
  "result": {
    "markdown": "---\ntitle: \"Clustering\"\nsubtitle: \"Using Python to Group Data Based on Similarities\"\nauthor: \"Aniket Adhikari\"\ndate: \"2023-11-15\"\ndate-modified: \"2023-11-16\"\ntoc: true\ntoc-title: \"On this page\"\n\n---\n\n# Supervised Learning vs. Unsupervised Learning\nBefore we talk about clustering, we must address some integral concepts related to it: supervised and unsupervised learning. \n\n*Supervised learning* is a machine learning technique that is used to train/teach a machine using **labeled** data. Labeled data implies that the data is already tagged with the correct answer. Teaching the machine on labeled data allows for future data to be correctly predicted.  Under the umbrella of supervised learning, there are 2 categories of algorithms:\n\n* **Classification**: Output variable is a category, so we are looking to categorize the output\n* **Regression**: Output variable is a real value, so we are looking to predict the value of the output\n\n*Unsupervised Learning* is a machine learning technique that uses used to train/teach a machine using that isn’t labeled or classified. The machine is now responsible for grouping the data according to similarities in characteristics without prior training. This is much harder because there is no “teacher” here, meaning the machine is tasked with finding the hidden structure in the unlabeled data.  Under the umbrella of unsupervised  learning, there are 2 categories of algorithms:\n\n* **Clustering**: Grouping of cata to find similarities \n* **Association**: Discover riles that describe large portions of data\n\n|| Supervised Learning  | Unsupervised Learning |\n|--------|--------|--|\n| Input | Labeled Data  | Unlabeled, uncategorized |\n| Accuracy | Highly accurate   |Less acurate |\n| Output | Categorized or real values | Groupings|\n\n: Comparison of Supervised and Unsupervised Learning {tbl-colwidths=\"[25,25]\"}\n\n# What is Clustering?\nAs mentioned, clustering is a type of unsupervised learning. Here, we are grouping data so that each group, or cluster, exhibits similar qualities. Ultimately, the goal of clustering to uncover intrinsic patterns and structures within data that can be used for analysis. \n\n# How Does Clustering Work?\nAlgorithms that are focused on clustering measure similarity between data points across a set of features. Features should be continuous variables but can be categorical. However, categorical data needs special encoding. Data points in the cluster that appear close to each other based on the features are grouped together, which the data points that are far away are separated into different clusters. There are several approaches to clustering, including: \n\n* **K-Means**: Grouping of data points in K clusters by minimizing the intra-cluster sum-of-squares. This requires setting the number of clusters up front, as we’ll see in the application section.\n* **Hierarchial**: Hierarchy of clusters are built iteratively\n* **DBSCAN**: groups dense regions of points and considers the sparse areas as outliers. Intuitively detects arbitrary cluster shapes. \n* **Gaussian Mixture Models**: Fits data as a mixture of Gaussian distributions where clusters are modeled using mean and covariance parameters. \n\n# Clustering Use Cases\nSo when is it a good time to use clustering? As mentioned, the best time to use clustering would be when we have data that is unlabeled. The following are more specific reasons to use clustering\n\n1. **Exploratory Data Analysis**: Clustering can help to reveal intrinsic groups and patterns in data without prior knowledge. It can open the door for further analysis by uncovering segements that were previously unknown\n2. **Customer Segementation**: Cluster customers based on certain attributes like demographics, purchasing beahvior, and more to achieve targeted marketing\n3. **Social Network Analysis**: Identify communities within a social network by clustering nodes based on connectivity and usage patterns\n4. **Anomaly Detection**: Detect anomalous data points that might not fit into a cluster to detect potential fraud or network attacks.\n\n# K-Means Clustering\nK-Means is one of the most popular clustering algorithms that is used for discovering intrinsic groups in unlabeled data. The \n\nK-Means partitions a dataset into a predefined number of clusters, $k$. It does this by minimizing the sum of distances between each data point and its assigned centroid, also known as the within-cluster sum of squares (WCSS). \n\n## Process of K-Means Clustering?\n\n1. Select $k$ initial centroids for the clusters \n2. Assign each data point to its closest centroid point based on Euclidean distance \n3. Recompute the centroids as the mean of all data points assigned to that cluster\n4. Repeat steps 2-3 until convergence, meaning the centrods no longer change between iterations\n\n## Choosing the Number of Clusters $k$\nWhen choosing the number of clusters for K-Means it's important to choose the right number of clusters because it affects the quality of clustering. \n\nYou could simply try different integer values to represent $k$ through a process of guessing-and-checking. Then, you could examine which one of $k$ values produces clustering visuals that makes the most sense for your data. \n\nAnother way to select $k$ is the *elbow method*, which involves plotting the WCSS vs. $k$. The part of the curve that is shaped like an elbow will contain what is likely a good choice for the $k$\n\n![Elbow Method from O'Reilly](https://www.oreilly.com/api/v2/epubs/9781788295758/files/assets/995b8b58-06f1-4884-a2a1-f3648428e947.png)\n\n## Example of K-Means Clustering\nWe can actually apply K-Means clustering in Python. Similar to the last post, I want to demonstrate how that can be done in code using a dataset of Pokemon from Generations 1-7.\n\nFirst we can start off by importing the libraries that are needed for the code.\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nfrom sklearn.cluster import KMeans\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\n```\n:::\n\n\nWe are then going to want to load our data. Again, it's from the Pokemon dataset.\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\ndata = pd.read_csv(\"../../datasets/pokemon.csv\", sep=\",\")\ndata\n```\n\n::: {.cell-output .cell-output-display execution_count=2}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>attack</th>\n      <th>base_egg_steps</th>\n      <th>base_happiness</th>\n      <th>base_total</th>\n      <th>capture_rate</th>\n      <th>defense</th>\n      <th>experience_growth</th>\n      <th>height_m</th>\n      <th>hp</th>\n      <th>name</th>\n      <th>percentage_male</th>\n      <th>pokedex_number</th>\n      <th>sp_attack</th>\n      <th>sp_defense</th>\n      <th>speed</th>\n      <th>type1</th>\n      <th>type2</th>\n      <th>weight_kg</th>\n      <th>generation</th>\n      <th>is_legendary</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>49</td>\n      <td>5120</td>\n      <td>70</td>\n      <td>318</td>\n      <td>45</td>\n      <td>49</td>\n      <td>1059860</td>\n      <td>0.7</td>\n      <td>45</td>\n      <td>Bulbasaur</td>\n      <td>88.1</td>\n      <td>1</td>\n      <td>65</td>\n      <td>65</td>\n      <td>45</td>\n      <td>grass</td>\n      <td>poison</td>\n      <td>6.9</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>62</td>\n      <td>5120</td>\n      <td>70</td>\n      <td>405</td>\n      <td>45</td>\n      <td>63</td>\n      <td>1059860</td>\n      <td>1.0</td>\n      <td>60</td>\n      <td>Ivysaur</td>\n      <td>88.1</td>\n      <td>2</td>\n      <td>80</td>\n      <td>80</td>\n      <td>60</td>\n      <td>grass</td>\n      <td>poison</td>\n      <td>13.0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>100</td>\n      <td>5120</td>\n      <td>70</td>\n      <td>625</td>\n      <td>45</td>\n      <td>123</td>\n      <td>1059860</td>\n      <td>2.0</td>\n      <td>80</td>\n      <td>Venusaur</td>\n      <td>88.1</td>\n      <td>3</td>\n      <td>122</td>\n      <td>120</td>\n      <td>80</td>\n      <td>grass</td>\n      <td>poison</td>\n      <td>100.0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>52</td>\n      <td>5120</td>\n      <td>70</td>\n      <td>309</td>\n      <td>45</td>\n      <td>43</td>\n      <td>1059860</td>\n      <td>0.6</td>\n      <td>39</td>\n      <td>Charmander</td>\n      <td>88.1</td>\n      <td>4</td>\n      <td>60</td>\n      <td>50</td>\n      <td>65</td>\n      <td>fire</td>\n      <td>NaN</td>\n      <td>8.5</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>64</td>\n      <td>5120</td>\n      <td>70</td>\n      <td>405</td>\n      <td>45</td>\n      <td>58</td>\n      <td>1059860</td>\n      <td>1.1</td>\n      <td>58</td>\n      <td>Charmeleon</td>\n      <td>88.1</td>\n      <td>5</td>\n      <td>80</td>\n      <td>65</td>\n      <td>80</td>\n      <td>fire</td>\n      <td>NaN</td>\n      <td>19.0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>796</th>\n      <td>101</td>\n      <td>30720</td>\n      <td>0</td>\n      <td>570</td>\n      <td>25</td>\n      <td>103</td>\n      <td>1250000</td>\n      <td>9.2</td>\n      <td>97</td>\n      <td>Celesteela</td>\n      <td>NaN</td>\n      <td>797</td>\n      <td>107</td>\n      <td>101</td>\n      <td>61</td>\n      <td>steel</td>\n      <td>flying</td>\n      <td>999.9</td>\n      <td>7</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>797</th>\n      <td>181</td>\n      <td>30720</td>\n      <td>0</td>\n      <td>570</td>\n      <td>255</td>\n      <td>131</td>\n      <td>1250000</td>\n      <td>0.3</td>\n      <td>59</td>\n      <td>Kartana</td>\n      <td>NaN</td>\n      <td>798</td>\n      <td>59</td>\n      <td>31</td>\n      <td>109</td>\n      <td>grass</td>\n      <td>steel</td>\n      <td>0.1</td>\n      <td>7</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>798</th>\n      <td>101</td>\n      <td>30720</td>\n      <td>0</td>\n      <td>570</td>\n      <td>15</td>\n      <td>53</td>\n      <td>1250000</td>\n      <td>5.5</td>\n      <td>223</td>\n      <td>Guzzlord</td>\n      <td>NaN</td>\n      <td>799</td>\n      <td>97</td>\n      <td>53</td>\n      <td>43</td>\n      <td>dark</td>\n      <td>dragon</td>\n      <td>888.0</td>\n      <td>7</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>799</th>\n      <td>107</td>\n      <td>30720</td>\n      <td>0</td>\n      <td>600</td>\n      <td>3</td>\n      <td>101</td>\n      <td>1250000</td>\n      <td>2.4</td>\n      <td>97</td>\n      <td>Necrozma</td>\n      <td>NaN</td>\n      <td>800</td>\n      <td>127</td>\n      <td>89</td>\n      <td>79</td>\n      <td>psychic</td>\n      <td>NaN</td>\n      <td>230.0</td>\n      <td>7</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>800</th>\n      <td>95</td>\n      <td>30720</td>\n      <td>0</td>\n      <td>600</td>\n      <td>3</td>\n      <td>115</td>\n      <td>1250000</td>\n      <td>1.0</td>\n      <td>80</td>\n      <td>Magearna</td>\n      <td>NaN</td>\n      <td>801</td>\n      <td>130</td>\n      <td>115</td>\n      <td>65</td>\n      <td>steel</td>\n      <td>fairy</td>\n      <td>80.5</td>\n      <td>7</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>801 rows × 20 columns</p>\n</div>\n```\n:::\n:::\n\n\nRecall that clustering requires features to be **continuous variables**. In this dataset, we have a couple of different continuous variables, such as:\n\n* `attack`\n* `defense`\n* `base_total`\n* `sp_attack`\n* `sp_defense`\n* `height_m`\n* `percentage_male`\n* `speed`\n* `weight_kg`\n\nSome of these variables are kind of useless though because they aren't going to give us anything interesting. Instead we want to focus on the stats associated with each Pokemon. More specifically, we want to focus on \n\n* `attack`\n* `defense`\n* `sp_attack`\n* `sp_defense`\n\nHonestly, I had trouble trying to decide on whether I wanted to cluster based on `attack` and `defense` or `sp_attack` and `sp_defense`. As a result, I ended up combining them in a way so that `attack` and `sp_attack` add up to `total_attack` and `defense` and `sp_defense` add up to `total_defense`. \n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\ndata['Total Attack'] = data['attack'] + data['sp_attack']\ndata['Total Defense'] = data['defense'] + data['sp_defense']\n```\n:::\n\n\nHere we are storing data for `total_attack` and `total_defense` into variable `X`\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\nx_val = 'Total Attack'\ny_val = 'Total Defense'\nvalues = [x_val, y_val]\nX = data[values] \n```\n:::\n\n\nAfter we have our data, we need to determine the number of clusters, or $k$. This is up to you, but I wanted to cluster it by 3 so we can have clusters of **weak**, **intermediate**, and **strong**. \n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\nkmeans = KMeans(n_clusters=3)\n```\n:::\n\n\nWe then need to compute the K-Means clusters by using the `fit()` function. Here we supply the method with the data that was gathered earlier.\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\nkmeans.fit(X)\n```\n\n::: {.cell-output .cell-output-display execution_count=6}\n```{=html}\n<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KMeans(n_clusters=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KMeans</label><div class=\"sk-toggleable__content\"><pre>KMeans(n_clusters=3)</pre></div></div></div></div></div>\n```\n:::\n:::\n\n\nWe can then store the labels of the cluster into `labels` so that it can be used for applying colors to each cluster with the `colormap` array\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\nlabels = kmeans.labels_\ncolormap = np.array(['red', 'green', 'blue'])\n```\n:::\n\n\nAfterwards, we are going to actually plot a scatter graph of the clustered data, using `total_attack` and `total_defense` as features\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\nplt.scatter(X['Total Attack'], X['Total Defense'], c=colormap[labels])\nplt.title('Pokemon Attack and Defense Clusters')\nplt.xlabel('Total Attack')\nplt.ylabel('Total Defense')\n\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](post2_files/figure-html/cell-9-output-1.png){width=593 height=449}\n:::\n:::\n\n\nIn the above clustering, data points labeled in red are considered \"weak\", green are considered \"intermediate\", and blue is considered \"strong.\n\nI'm going to be replaying Pokemon games over the winter break so I'm hoping this scatter will give me an indication as to what Pokemon I should catch!\n\n# Gaussian Mixture Models (GMMs)\nGausian Mixture Models (GMMs) are probabilistic models that assumes data points are generated from a mixture of Gaussian distributions. GMMs are a popular clustering algorithm with applications such as density estimation, data compression, and more. \n\n## How Does GMMs Work\nA GMM models each cluster as a Gaussian distribuion, characterized by a mean and covariance matrix. The complete model is a weighted sum of the component Gaussian densities.\n\nThe GMM fitting process determines the parameters of each Gaussian as well as the mixture weights. This is done through iterative expectation-maximiation algorithm that converges to find the maximum likelihood estimates.\n\nThe number of Gaussian components corresponds to the number of clusters. Choosing the right number of clusters is important to avoid underfitting or overfitting.\n\n## Example of GMM\nHere we are importing a couple of different libraries that have been used before. We are importing `GaussianMixture` in order to create Gaussian Mixture Models.\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\nimport pandas as pd\nfrom sklearn.mixture import GaussianMixture\nimport matplotlib.pyplot as plt\n```\n:::\n\n\nThe dataset being imported consists of customer data, including information such as \n\n* `Gender`\n* `Age`\n* `Annual Income ($)`\n* `Spending Score (1-100)`\n* `Profession`\n* `Work Experience`\n* `Family Size`\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\ncustomer_data = pd.read_csv('../../datasets/Customers.csv')\n```\n:::\n\n\nI am particularly interested in using variables that are continuous, which are `Age`, `Annual Income`, and `Work Experience`. We are using these variables as features for segmentation\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\nselected_features = ['Age', 'Annual Income ($)', 'Work Experience']\n```\n:::\n\n\nHere we are preprocessing by extracting and scaling the selected features\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\ncustomer_features = customer_data[selected_features]\ncustomer_features = (customer_features - customer_features.mean()) / customer_features.std()\n```\n:::\n\n\nWe can create a GMM by creating 3 clusters of the data and then fitting it based on the preprocessed data. \n\nWe are then predicting the labels and then assigning it to a column called `Cluster`\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\nnum_clusters = 3\ngmm = GaussianMixture(n_components=num_clusters)\ngmm.fit(customer_features)\ncluster_labels = gmm.predict(customer_features)\ncustomer_data['Cluster'] = cluster_labels\n```\n:::\n\n\nFinally, we plot the data on a scatterplot using `Age` and `Annual Income ($)`.\n\n::: {.cell execution_count=14}\n``` {.python .cell-code}\nplt.scatter(x=customer_data[\"Age\"], y=customer_data[\"Annual Income ($)\"], c=cluster_labels, cmap=\"Set1\")\nplt.xlabel(\"Age\")\nplt.ylabel(\"Income\")\nplt.suptitle('Customer Segmentation using GMM')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](post2_files/figure-html/cell-15-output-1.png){width=619 height=477}\n:::\n:::\n\n\n",
    "supporting": [
      "post2_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}